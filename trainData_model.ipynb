{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6mt9nrS0qC7"
      },
      "source": [
        "# **Road Following - Training Model**\n",
        "\n",
        "We will train a neural network to take an input image and output a set of x,y values ​​corresponding to a target.\n",
        "\n",
        "We will use the **PyTorch** deep learning framework to train a **ResNet18** neural network architecture model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-voejcA0qC8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import glob\n",
        "import PIL.Image\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug4oPUSf0qC9"
      },
      "source": [
        "## **1. Create a dataset instance**\n",
        "Customize a class ``torch.utils.data.Dataset`` and implement the ``__len__`` and ``__getitem__`` function methods. This class is responsible for loading images and parsing x, y values ​​from image file names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sIFfyTX0qC9"
      },
      "outputs": [],
      "source": [
        "class XYDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, directory, target_number=1, random_hflips=False):\n",
        "        self.directory = directory\n",
        "        self.target_number = target_number\n",
        "        self.random_hflips = random_hflips\n",
        "        self.image_paths = glob.glob(os.path.join(self.directory, '*.jpg'))\n",
        "        self.color_jitter = transforms.ColorJitter(0.3, 0.3, 0.3, 0.3)\n",
        "\n",
        "    def get_label(self, path):\n",
        "        label = []\n",
        "        for i in range(self.target_number):\n",
        "            offset = 8*i+3\n",
        "            target_x = (float(int(path[offset: offset+3]))- 50.0) / 50.0\n",
        "            target_y = (float(int(path[offset+4 : offset+7])) - 50.0) / 50.0\n",
        "            label.append(target_x)\n",
        "            label.append(target_y)\n",
        "            #target_x = float(int(path[3:6])（11：14）(19:22)\n",
        "            #target_y = float(int(path[7:10]))(15, 18)(23:26)\n",
        "        return torch.tensor(label).float()\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "\n",
        "        image = PIL.Image.open(image_path)\n",
        "\n",
        "        label = self.get_label(os.path.basename(image_path))\n",
        "        #x = float(get_x(os.path.basename(image_path)))\n",
        "        #y = float(get_y(os.path.basename(image_path)))\n",
        "        '''data enhanced'''\n",
        "\n",
        "        if self.random_hflips:\n",
        "            if float(np.random.rand(1)) > 0.5:\n",
        "                image = transforms.functional.hflip(image)\n",
        "                x = -x\n",
        "\n",
        "        image = self.color_jitter(image)\n",
        "        image = transforms.functional.resize(image,(224, 224))\n",
        "        image = transforms.functional.to_tensor(image)\n",
        "        image = image.numpy()[::-1].copy()\n",
        "        image = torch.from_numpy(image)\n",
        "        image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "\n",
        "        return image, label#torch.tensor([x, y]).float()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj49txfN0qC-"
      },
      "outputs": [],
      "source": [
        "dataset = XYDataset('data/dataset_xy', 2, random_hflips=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTkopsh90qC-"
      },
      "source": [
        "## **1. Create a dataset instance**\n",
        "Customize a class ``torch.utils.data.Dataset`` and implement the ``__len__`` and ``__getitem__`` function methods. This class is responsible for loading images and parsing x, y values ​​​​from image file names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x67YnSmD0qC-"
      },
      "outputs": [],
      "source": [
        "test_percent = 0.3\n",
        "num_test = int(test_percent * len(dataset))\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asrcONuh0qC-"
      },
      "source": [
        "## **3. Create a data loader to load data in batches**\n",
        "Use ``DataLoader class`` to load data in batches. This container allows multiple subprocesses and shuffle data. The batch size we use is 8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N68cecCo0qC-"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN2W_lcn0qC-"
      },
      "source": [
        "## **4. Define the neural network**\n",
        "We use the ``ResNet-18`` model on **PyTorch TorchVision** and load the pre-trained model for **transfer learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbhIuUJA0qC_"
      },
      "outputs": [],
      "source": [
        "target_number = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2Yc99ra0qC_"
      },
      "outputs": [],
      "source": [
        "model = models.resnet18(pretrained=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc-R2QbL0qC_"
      },
      "source": [
        "The ResNet model has 512 as the fully connected (fc) final layer of ``in_features``, and we will be doing regression training, so ``out_features`` is **2 x target_number**\n",
        "\n",
        "Finally, train the model on the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_XFFvNi0qC_"
      },
      "outputs": [],
      "source": [
        "model.fc = torch.nn.Linear(512, 2*target_number)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-5pCpKI0qC_"
      },
      "source": [
        "## **5. Define training parameters**\n",
        "\n",
        "#### 5.1 Define visualization tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tMhF07N0qC_"
      },
      "outputs": [],
      "source": [
        "import ipywidgets\n",
        "'''parameters'''\n",
        "epochs_widget = ipywidgets.IntText(description='epochs', value=50)\n",
        "model_path_widget = ipywidgets.Text(description='model path', value='model/road_following_model.pth')\n",
        "'''training'''\n",
        "steps_widget = ipywidgets.IntText(description='steps', value=0)\n",
        "train_progress_widget = ipywidgets.FloatProgress(min=0.0, max=1.0, description='progress')\n",
        "train_loss_widget = ipywidgets.FloatText(description='train loss')\n",
        "eval_progress_widget = ipywidgets.FloatProgress(min=0.0, max=1.0, description='progress')\n",
        "eval_loss_widget = ipywidgets.FloatText(description='eval loss')\n",
        "save_info_widget = ipywidgets.Text(description='save info')\n",
        "train_button = ipywidgets.Button(description='START', button_style='warning',layout=ipywidgets.Layout(width='300px', height='28px'))\n",
        "\n",
        "train_eval_widget = ipywidgets.VBox([\n",
        "    ipywidgets.Label('-'*31+'parameters'+'-'*31),\n",
        "    epochs_widget,\n",
        "    model_path_widget,\n",
        "    ipywidgets.Label('-'*29+'training'+'-'*29),\n",
        "    steps_widget,\n",
        "    train_progress_widget,\n",
        "    train_loss_widget,\n",
        "    eval_progress_widget,\n",
        "    eval_loss_widget,\n",
        "    save_info_widget,\n",
        "    ipywidgets.Label('-'*70),\n",
        "    train_button\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "052vXezs0qC_"
      },
      "source": [
        "#### 5.2 Define training parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGJuJ4lf0qC_"
      },
      "outputs": [],
      "source": [
        "def train_eval(change):\n",
        "    global model\n",
        "    NUM_EPOCHS = epochs_widget.value\n",
        "    MODEL_PATH = model_path_widget.value # save path\n",
        "    best_loss = 1e9 # loss\n",
        "    BAST_MODEL_PATH = 'best_' + MODEL_PATH\n",
        "    LAST_MODEL_PATH = 'last_' + MODEL_PATH\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters())# optimizer\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        steps_widget.value = epoch\n",
        "        '''当前批次开始训练'''\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for index,(images, labels) in enumerate(iter(train_loader)):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad() # Optimizer gradients cleared\n",
        "            outputs = model(images)\n",
        "            loss = F.mse_loss(outputs, labels)# mean square loss\n",
        "            train_loss += float(loss) # cumulative loss\n",
        "            loss.backward() # back propagation to calculate reverse gradient\n",
        "            optimizer.step() # optimizer updates network parameters\n",
        "            train_progress_widget.value = (index+1)/len(train_loader)# loading\n",
        "            train_loss_widget.value = loss # display loss\n",
        "        train_loss /= len(train_loader) # average loss\n",
        "        train_loss_widget.value = train_loss # display loss\n",
        "\n",
        "        '''Current batch starts verification'''\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        for index, (images, labels) in enumerate(iter(test_loader)):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = F.mse_loss(outputs, labels)\n",
        "            test_loss += float(loss)\n",
        "            '''Display verification results'''\n",
        "            eval_progress_widget.value = (index+1)/len(test_loader)\n",
        "            eval_loss_widget.value = loss\n",
        "        test_loss /= len(test_loader)\n",
        "        eval_loss_widget.value = test_loss\n",
        "\n",
        "        print('%f, %f' % (train_loss, test_loss))\n",
        "        torch.save(model.state_dict(), LAST_MODEL_PATH)\n",
        "        if test_loss < best_loss:\n",
        "            torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
        "            best_loss = test_loss\n",
        "            save_info_widget.value = 'step %d (train: %.4f, eval: %.4f)'%(epoch, train_loss, test_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQgNkoA60qDA"
      },
      "outputs": [],
      "source": [
        "train_button.on_click(train_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8m0pV8N0qDA"
      },
      "source": [
        "SAVE ``best_steering_model_xy.pth``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLRWp2RR0qDA"
      },
      "source": [
        "#### 5.3 Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbae1FPG0qDA"
      },
      "outputs": [],
      "source": [
        "display(train_eval_widget)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJfqMR8-0qDB"
      },
      "source": [
        "---\n",
        "Parameters\n",
        "\n",
        "``epochs_widget``: Set the number of training iterations\n",
        "\n",
        "``save_model_widget``: Set the model save path\n",
        "\n",
        "---\n",
        "Training process\n",
        "\n",
        "``steps_widget``: Display the current iteration id\n",
        "\n",
        "``train_progress_widget``: Display the progress of the current batch training part\n",
        "\n",
        "``train_loss_widget``: Display the loss of the current batch training part\n",
        "\n",
        "``eval_progress_widget``: Display the progress of the current batch training part\n",
        "\n",
        "``eval_loss_widget``: Display the loss of the current batch training part\n",
        "\n",
        "``save_info_widget``: Display the steps of the current epochs, total loss and whether to save\n",
        "\n",
        "---\n",
        "Training switch\n",
        "\n",
        "``train_button``"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}